{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedure\n",
    "- Read and show video stream , capture images\n",
    "- Detect Fces and show bounding box\n",
    "- Flatten the Largest face image and save in numpy array\n",
    "- Repeat the above for multiple people to generate training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init camera\n",
    "capture = cv2.VideoCapture(0)\n",
    "#face detection\n",
    "face_cascade_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_alt.xml\")\n",
    "skip = 0\n",
    "face_data = []\n",
    "dataset_path = \"./data/\"\n",
    "filename=input('enter name of person : ')\n",
    "while True:\n",
    "    ret,frame = capture.read()\n",
    "    if ret==False:\n",
    "        continue\n",
    "    gray_frame = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    faces=face_cascade_classifier.detectMultiScale(frame,1.3,5)\n",
    "    #pick largest face(bcz area is i[2]*i[3]) \n",
    "    faces = sorted(faces,key=lambda i:i[2]*i[3])\n",
    "    for face in faces[-1:]:\n",
    "        x,y,w,h = face\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "    #croping required face : Region of Interest\n",
    "    offset = 10\n",
    "    face_section = frame[y-offset:y+h+offset,x-offset:x+w+offset]\n",
    "    \n",
    "    #resize into 100x100\n",
    "    face_section = cv2.resize(face_section,(100,100))\n",
    "    \n",
    "    if skip%10==0:\n",
    "        face_data.append(face_section)\n",
    "        print(len(face_data))\n",
    "    skip+=1\n",
    "    cv2.imshow(\"Video Frame\",frame)\n",
    "    cv2.imshow(\"Face Frame\",face_section)\n",
    "    \n",
    "    key_pressed = cv2.waitKey(1)&0XFF\n",
    "    if key_pressed == ord('q'):\n",
    "        break\n",
    "        \n",
    "#convert our face list array into numpy array\n",
    "face_data = np.asarray(face_data)\n",
    "#print(face_data.shape)\n",
    "#print(face_data.shape[0])\n",
    "face_data = face_data.reshape((face_data.shape[0],-1))\n",
    "#print(face_data.shape)\n",
    "#save this data into file system\n",
    "np.save(dataset_path+filename+'.npy',face_data)\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read video Stream using openCV<br>\n",
    "2. Extract Faces out of it.<br>\n",
    "3. Load the training data(numpy arrays of the person)<br>\n",
    "    x values are stored in arrays<br>\n",
    "    y values we need to assign for each person<br>\n",
    "4. Use KNN to find prediction of the face\n",
    "5. Map the predicted name of the user\n",
    "6. Display prediction on screen\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the Euclidean distance between two vectors\n",
    "import math\n",
    "def Euc_distance(x,y,K=5):\n",
    "    distance=[]\n",
    "    for i in range(y.shape[0]):\n",
    "        dis = math.sqrt((query_point[0]-x[i][0])**2+(query_point[1]-x[i][1])**2)\n",
    "        distance.append((dis,y[i]))\n",
    "    distance.sort()\n",
    "    distance=distance[0:K]\n",
    "    return distance\n",
    "def KNN(x,y,K=5):\n",
    "    distance=Euc_distance(x,y)\n",
    "    classes=[]\n",
    "    for i in range(K):\n",
    "        classes.append(distance[i][1])\n",
    "    return np.unique(classes,return_counts=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init camera\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "#face detection\n",
    "face_cascade_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_alt.xml\")\n",
    "skip = 0\n",
    "\n",
    "#face_data is training data\n",
    "face_data = []\n",
    "labels=[]\n",
    "#load datset\n",
    "dataset_path = \"./data/\"\n",
    "\n",
    "class_id = 0 \n",
    "name = {} #mapping between id and name\n",
    "\n",
    "#Data Preparation\n",
    "for fx in os.listdir(dataset_path):\n",
    "    if fx.endswith('.npy'):\n",
    "        data_item = np.load(dataset_path+fx)\n",
    "        face_data.append(data_item)\n",
    "        \n",
    "        #Create Labels for the class\n",
    "        target = class_id*np.ones((data_item.shape[0],))\n",
    "        class_id+=1\n",
    "        labels.append(target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
